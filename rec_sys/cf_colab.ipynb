{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": []
    },
    {
      "metadata": {
        "id": "fa308cfc4e877d7"
      },
      "cell_type": "markdown",
      "source": [
        "# MMD 2024, Collaborative Filtering on Google Colab\n",
        "This notebook sets up the enviroment and runs CF experiments on Google Colab.\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "fa308cfc4e877d7"
    },
    {
      "metadata": {
        "id": "7150cc4ffafd8dcf"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 1,
      "source": [
        "# Clone the repository to local runtime\n",
        "\n",
        "private = False\n",
        "if private:\n",
        "    # Private repository, requires authentication\n",
        "    from google.colab import userdata\n",
        "    pat = userdata.get('github_pat')\n",
        "    project = '24WS-mmd-code-priv'\n",
        "else:\n",
        "    pat = ''\n",
        "    project = '24WS-mmd-code-public'"
      ],
      "id": "7150cc4ffafd8dcf"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4af0ee9ef63060",
        "outputId": "beb2d8f4-e115-4685-dca1-b50cedd0e8cb"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '24WS-mmd-code-public'...\n",
            "warning: redirecting to https://github.com/aip-hd-tea/24WS-mmd-code-public.git/\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 41 (delta 0), reused 0 (delta 0), pack-reused 38 (from 1)\u001b[K\n",
            "Receiving objects: 100% (41/41), 13.45 KiB | 1.34 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "execution_count": 2,
      "source": [
        "!git clone https://{pat}@github.com/aip-hd-tea/{project}.git"
      ],
      "id": "de4af0ee9ef63060"
    },
    {
      "metadata": {
        "id": "cc23bb7c89f22488"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 3,
      "source": [
        "# Import the repository code\n",
        "import sys\n",
        "sys.path.insert(0,f\"/content/{project}\")\n",
        "\n",
        "import rec_sys.data_util as cfd\n",
        "\n",
        "# After edits of cf_algorithms_to_complete.py:\n",
        "# 1. Rename the file rec_sys.cf_algorithms_to_complete.py to rec_sys.cf_algorithms.py\n",
        "# 2. Restart the runtime (Runtime -> Restart the session); possibly not needed\n",
        "# 3. Swap the comments in the next two lines, so that cf_algorithms is imported as cfa\n",
        "import rec_sys.cf_algorithms_to_complete as cfa\n",
        "#import rec_sys.cf_algorithms as cfa\n",
        "# 4. Re-run all cells\n",
        "# 5. If your changes are correct, you will see a long\n",
        "#    printout of recommendations for MovieLens dataset (last cell)"
      ],
      "id": "cc23bb7c89f22488"
    },
    {
      "metadata": {
        "id": "3a20780ceb8a3f69"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 4,
      "source": [
        "# Load or set the configuration\n",
        "#from rec_sys.cf_config import config\n",
        "\n",
        "import dataclasses\n",
        "@dataclasses.dataclass\n",
        "class config:\n",
        "    max_rows: int = int(1e5)\n",
        "    dowload_url: str = \"https://files.grouplens.org/datasets/movielens/ml-25m.zip\"\n",
        "    download_dir: str = \"/content/\"\n",
        "    unzipped_dir: str = download_dir + \"ml-25m/\"\n",
        "    file_path: str = download_dir + \"ml-25m/ratings.csv\"\n"
      ],
      "id": "3a20780ceb8a3f69"
    },
    {
      "metadata": {
        "id": "de5038d900469236"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Load the MovieLens and Lecture datasets\n",
        "um_movielens = cfd.get_um_by_name(config, \"movielens\")\n",
        "um_lecture = cfd.get_um_by_name(config, \"lecture_1\")\n",
        "\n",
        "# Rate all items for the lecture toy dataset\n",
        "all_ratings = cfa.rate_all_items(um_lecture, 4, 2)\n",
        "print (\"all_ratings lecture toy dataset:\", all_ratings)\n",
        "\n",
        "# Rate all items the MovieLens data\n",
        "all_ratings_movielens = cfa.rate_all_items(um_movielens, 0, 2)\n",
        "print(\"all_ratings_movielens:\", all_ratings_movielens)"
      ],
      "id": "de5038d900469236"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import jax.numpy as jnp\n",
        "from jax import grad\n",
        "from jax import jit\n",
        "import jax\n",
        "import rec_sys.config\n",
        "import rec_sys.lf_algorithms\n",
        "import itertools\n",
        "import rec_sys.data_util as data  # Fix missing import for data_util\n",
        "\n",
        "# Mount Google Drive to access data\n",
        "# This will help in saving models or logs if needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgfEgGBQvtDG",
        "outputId": "a5f6c775-6cd8-4ba5-a25c-2a23ab8c4f25"
      },
      "id": "YgfEgGBQvtDG",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Implement uv_factorization_reg with regularization and JIT compilation\n",
        "\n",
        "def uv_factorization_reg(train_ds, num_users, num_items, rank, num_epochs, learning_rate, reg_param):\n",
        "    \"\"\"\n",
        "    Implements SGD for UV factorization with regularization terms for matrix approximation.\n",
        "\n",
        "    Parameters:\n",
        "    - train_ds: Training dataset (as a TensorFlow Dataset)\n",
        "    - num_users: Number of users\n",
        "    - num_items: Number of items\n",
        "    - rank: Number of latent factors\n",
        "    - num_epochs: Number of iterations for SGD\n",
        "    - learning_rate: Learning rate for SGD\n",
        "    - reg_param: Regularization parameter\n",
        "\n",
        "    Returns:\n",
        "    - U: User matrix (n_users x rank)\n",
        "    - V: Item matrix (rank x n_items)\n",
        "    \"\"\"\n",
        "    # Initialize user and item matrices U and V with random values\n",
        "    rng_key = jax.random.PRNGKey(0)\n",
        "    U, V = init_latent_factors(num_users, num_items, rank, rng_key)\n",
        "\n",
        "    def loss_fn(u, v, rating, i, j):\n",
        "        \"\"\"Computes the regularized loss for a given pair (i, j).\"\"\"\n",
        "        error = rating - jnp.dot(u[i, :], v[:, j])\n",
        "        reg_term = reg_param * (jnp.sum(jnp.square(u[i, :])) + jnp.sum(jnp.square(v[:, j])))\n",
        "        return error ** 2 + reg_term\n",
        "\n",
        "    grad_u = jit(grad(loss_fn, 0))  # JIT compile the gradient calculations\n",
        "    grad_v = jit(grad(loss_fn, 1))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in train_ds.batch(128):  # Process records in batches of 128 for efficiency\n",
        "            # Convert TensorFlow tensors to NumPy arrays for JAX compatibility\n",
        "            i = jnp.array(batch[\"user_id\"].numpy())\n",
        "            j = jnp.array(batch[\"movie_id\"].numpy())\n",
        "            rating = jnp.array(batch[\"user_rating\"].numpy())\n",
        "\n",
        "            for idx in range(len(i)):\n",
        "                dU = grad_u(U, V, rating[idx], i[idx], j[idx])  # Ensure gradient has correct shape automatically\n",
        "                dV = grad_v(U, V, rating[idx], i[idx], j[idx])  # Ensure gradient has correct shape automatically\n",
        "\n",
        "                # Update the user and item matrices element-wise using index_update to directly set values\n",
        "                U = U.at[i[idx], :].set(U[i[idx], :] - learning_rate * dU[i[idx], :])\n",
        "                V = V.at[:, j[idx]].set(V[:, j[idx]] - learning_rate * dV[:, j[idx]])\n",
        "\n",
        "    return U, V\n",
        "\n",
        "# Load configuration and data\n",
        "config = ConfigLf()\n",
        "ratings_tf, user_ids_voc, movie_ids_voc = data.load_movielens_tf(config)  # Load data using data_util\n",
        "num_users = len(user_ids_voc.get_vocabulary())\n",
        "num_items = len(movie_ids_voc.get_vocabulary())\n",
        "rng_key_factors, rng_key_r = jax.random.split(jax.random.PRNGKey(config.rng_seed))\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "train_ds, valid_ds, test_ds = data.split_train_valid_test_tf(ratings_tf, config)\n",
        "\n",
        "# Initialize latent factors\n",
        "U, V = init_latent_factors(num_users, num_items, config.num_factors, rng_key_factors)\n",
        "\n",
        "# Set hyperparameters\n",
        "rank = config.num_factors\n",
        "num_epochs = 5  # Reduce the number of epochs to speed up computation\n",
        "learning_rate = config.fixed_learning_rate if config.fixed_learning_rate else 0.01\n",
        "reg_param = config.reg_param\n",
        "\n",
        "# Run regularized factorization\n",
        "print(\"Running regularized UV factorization...\")\n",
        "U_reg, V_reg = uv_factorization_reg(train_ds, num_users, num_items, rank, num_epochs, learning_rate, reg_param)\n",
        "\n",
        "# Compare convergence and accuracy\n",
        "U_no_reg, V_no_reg = init_latent_factors(num_users, num_items, rank, jax.random.PRNGKey(1))\n",
        "# Inline function to show metrics and examples\n",
        "def show_metrics_and_examples(U_no_reg, V_no_reg, U_reg, V_reg, test_ds):\n",
        "    print(\"\\n====== Metrics and Examples ======\")\n",
        "    # Compute and print MSE for both regularized and non-regularized matrices\n",
        "    mse_no_reg = jnp.mean((test_ds - U_no_reg @ V_no_reg) ** 2)\n",
        "    mse_reg = jnp.mean((test_ds - U_reg @ V_reg) ** 2)\n",
        "    print(f\"MSE without regularization: {mse_no_reg}\")\n",
        "    print(f\"MSE with regularization: {mse_reg}\")\n",
        "\n",
        "# Call the function to show metrics and examples\n",
        "show_metrics_and_examples(U_no_reg, V_no_reg, U_reg, V_reg, test_ds)\n",
        "\n",
        "# Hyperparameter grid search\n",
        "learning_rates = jnp.linspace(0.01, 0.05, 3)  # Reduce the range to speed up grid search\n",
        "reg_params = jnp.linspace(0.1, 0.5, 3)  # Reduce the range to speed up grid search\n",
        "\n",
        "def grid_search(train_ds, valid_ds, num_users, num_items, rank, num_epochs, learning_rates, reg_params):\n",
        "    \"\"\"\n",
        "    Conducts a grid search over hyperparameters and returns the best result.\n",
        "\n",
        "    Parameters:\n",
        "    - train_ds: Training dataset\n",
        "    - valid_ds: Validation dataset\n",
        "    - num_users: Number of users\n",
        "    - num_items: Number of items\n",
        "    - rank: Number of latent factors\n",
        "    - num_epochs: Number of epochs for training\n",
        "    - learning_rates: List of learning rates to test\n",
        "    - reg_params: List of regularization parameters to test\n",
        "\n",
        "    Returns:\n",
        "    - Best hyperparameter values and corresponding U and V matrices\n",
        "    \"\"\"\n",
        "    best_loss = float('inf')\n",
        "    best_params = None\n",
        "    best_U, best_V = None, None\n",
        "\n",
        "    for lr, reg in itertools.product(learning_rates, reg_params):\n",
        "        print(f\"Testing learning_rate: {lr}, reg_param: {reg}\")\n",
        "        U, V = uv_factorization_reg(train_ds, num_users, num_items, rank, num_epochs, lr, reg)\n",
        "        # Evaluate loss (using validation set)\n",
        "        valid_loss = jnp.mean((valid_ds - U @ V) ** 2)  # Mean Squared Error on validation set\n",
        "        print(f\"Validation Loss: {valid_loss}\")\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            best_params = (lr, reg)\n",
        "            best_U, best_V = U, V\n",
        "\n",
        "    print(f\"Best hyperparameters: Learning Rate = {best_params[0]}, Regularization = {best_params[1]}\")\n",
        "    return best_U, best_V\n",
        "\n",
        "# Perform grid search to find best hyperparameters\n",
        "print(\"Performing grid search for hyperparameters...\")\n",
        "U_best, V_best = grid_search(train_ds, valid_ds, num_users, num_items, rank, num_epochs, learning_rates, reg_params)\n",
        "\n",
        "# Compare best model with the original models\n",
        "show_metrics_and_examples(U_no_reg, V_no_reg, U_best, V_best, test_ds)\n"
      ],
      "metadata": {
        "id": "4Cl7K8vyytvx",
        "outputId": "c28fb06d-79f6-4dc4-c611-740a39de852b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        }
      },
      "id": "4Cl7K8vyytvx",
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded dataset 'movielens/100k' with 100000 ratings and features: FeaturesDict({\n",
            "    'bucketized_user_age': float32,\n",
            "    'movie_genres': Sequence(ClassLabel(shape=(), dtype=int64, num_classes=21)),\n",
            "    'movie_id': string,\n",
            "    'movie_title': string,\n",
            "    'raw_user_age': float32,\n",
            "    'timestamp': int64,\n",
            "    'user_gender': bool,\n",
            "    'user_id': string,\n",
            "    'user_occupation_label': ClassLabel(shape=(), dtype=int64, num_classes=22),\n",
            "    'user_occupation_text': string,\n",
            "    'user_rating': float32,\n",
            "    'user_zip_code': string,\n",
            "})\n",
            "Filtering tf dataset for user_id, movie_id and user_rating\n",
            "Creating a vocabulary for user_id (str -> int)\n",
            "Vocabulary of user_id's has size: 944\n",
            "Creating a vocabulary for movie_id (str -> int)\n",
            "Vocabulary of movie_id's has size: 1683\n",
            "Splitting the dataset into train, validation and test sets with sizes: (0.8, 0.1, 0.1)\n",
            "Absolute sizes => Train: 80000, Validation: 10000, Test: 10000\n",
            "Running regularized UV factorization...\n",
            "\n",
            "====== Metrics and Examples ======\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for -: '_TakeDataset' and 'jaxlib.xla_extension.ArrayImpl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0716c78289fa>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m# Call the function to show metrics and examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mshow_metrics_and_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU_no_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_no_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# Hyperparameter grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-0716c78289fa>\u001b[0m in \u001b[0;36mshow_metrics_and_examples\u001b[0;34m(U_no_reg, V_no_reg, U_reg, V_reg, test_ds)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n====== Metrics and Examples ======\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Compute and print MSE for both regularized and non-regularized matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mmse_no_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mU_no_reg\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mV_no_reg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mmse_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mU_reg\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mV_reg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"MSE without regularization: {mse_no_reg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: '_TakeDataset' and 'jaxlib.xla_extension.ArrayImpl'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1e53c31c16dcef07"
      },
      "cell_type": "markdown",
      "source": [],
      "id": "1e53c31c16dcef07"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKEZssZT3WOa"
      },
      "id": "jKEZssZT3WOa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}